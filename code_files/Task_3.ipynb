{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7921c2",
   "metadata": {},
   "source": [
    "### Automotive Efficiency Problem\n",
    "\n",
    "a) **Decision Tree Usage**  \n",
    "   - Show the usage of your decision tree for the **automotive efficiency problem**.  \n",
    "   **[0.5 marks]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cabb54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tree.base import DecisionTree\n",
    "from metrics import *\n",
    "from tree.utils import *\n",
    "from tree.add_utils import *\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "data = pd.read_csv(url, delim_whitespace=True, header=None,\n",
    "                 names=[\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\",\n",
    "                        \"acceleration\", \"model_year\", \"origin\", \"car_name\"])\n",
    "\n",
    "\n",
    "#Clean the data\n",
    "\n",
    "data['horsepower'] = pd.to_numeric(data['horsepower'], errors='coerce')\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "categorical_cols = ['cylinders', 'model_year', 'origin']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "data = data.drop(columns=['car_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c3dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_real(attr: pd.Series) -> bool:\n",
    "    if pd.api.types.is_categorical_dtype(attr) or attr.dtype == object:\n",
    "        return False\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(attr):\n",
    "        unique_vals = attr.nunique()\n",
    "        if unique_vals <= 5:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59738ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain_mse_real_real(x: pd.Series, y: pd.Series, threshold: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute information gain (based on MSE reduction) for a real-valued split.\n",
    "    \n",
    "    Args:\n",
    "        x : feature column (numeric)\n",
    "        y : target column (numeric)\n",
    "        threshold : numeric split value\n",
    "        \n",
    "    Returns:\n",
    "        gain : float\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"x\": x, \"y\": y})\n",
    "    \n",
    "    left_y = df[df[\"x\"] <= threshold][\"y\"]\n",
    "    right_y = df[df[\"x\"] > threshold][\"y\"]\n",
    "    \n",
    "    mse_total = ((y - y.mean())**2).mean()\n",
    "    mse_left = ((left_y - left_y.mean())**2).mean() if not left_y.empty else 0\n",
    "    mse_right = ((right_y - right_y.mean())**2).mean() if not right_y.empty else 0\n",
    "    \n",
    "    # Weighted MSE after split\n",
    "    w_mse = (len(left_y)/len(y)) * mse_left + (len(right_y)/len(y)) * mse_right\n",
    "    \n",
    "    gain = mse_total - w_mse\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625b7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_real_attribute(X: pd.DataFrame, y: pd.Series):\n",
    "    best_attr, best_split, best_gain = None, None, -float(\"inf\")\n",
    "\n",
    "    for col in X.columns:\n",
    "        if pd.api.types.is_numeric_dtype(X[col]):\n",
    "            values = sorted(X[col].unique())\n",
    "            for i in range(1, len(values)):\n",
    "                split = (values[i-1] + values[i]) / 2\n",
    "                gain = info_gain_mse_real_real(X[col], y, split)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_attr = col\n",
    "                    best_split = split\n",
    "\n",
    "    return best_attr, best_split, best_gain\n",
    "\n",
    "\n",
    "\n",
    "def best_discrete_attribute(X: pd.DataFrame, y: pd.Series):\n",
    "    best_attr, best_gain = None, -float(\"inf\")\n",
    "\n",
    "    for col in X.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(X[col]):\n",
    "            gain = info_gain_mse_disc_real(X[col], y)  \n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_attr = col\n",
    "\n",
    "    return best_attr, best_gain\n",
    "\n",
    "\n",
    "def best_attribute(X: pd.DataFrame, y: pd.Series):\n",
    "    real_attr, real_split, real_gain = best_real_attribute(X, y)\n",
    "    disc_attr, disc_gain = best_discrete_attribute(X, y)\n",
    "\n",
    "    if real_gain >= disc_gain:\n",
    "        return real_attr, real_split, real_gain, \"real\"\n",
    "    else:\n",
    "        return disc_attr, None, disc_gain, \"discrete\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9323fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTreeRealOutput:\n",
    "    def __init__(self, max_depth=10):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, attribute=None, threshold=None, left=None, right=None, value=None, is_real=True):\n",
    "            self.attribute = attribute      \n",
    "            self.threshold = threshold      \n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value              \n",
    "            self.is_real = is_real          \n",
    "\n",
    "    def fit(self, data: pd.DataFrame, target_col: str):\n",
    "        self.root = self._build_tree(data, target_col, depth=0)\n",
    "\n",
    "    def _build_tree(self, data, target_col, depth):\n",
    "        X = data.drop(columns=[target_col])\n",
    "        y = data[target_col]\n",
    "\n",
    "       \n",
    "        if depth >= self.max_depth or len(y.unique()) == 1 or X.empty:\n",
    "            return self.Node(value=y.mean())\n",
    "\n",
    "    \n",
    "        real_attr, real_split, real_gain = best_real_attribute(X, y)\n",
    "        disc_attr, disc_gain = best_discrete_attribute(X, y)\n",
    "\n",
    "        \n",
    "        if real_gain is None and disc_gain is None:\n",
    "            return self.Node(value=y.mean())\n",
    "        elif disc_gain is None or (real_gain is not None and real_gain >= disc_gain):\n",
    "            attr, split, is_real = real_attr, real_split, True\n",
    "        else:\n",
    "            attr, split, is_real = disc_attr, disc_gain, False\n",
    "\n",
    "        if attr is None:\n",
    "            return self.Node(value=y.mean())\n",
    "\n",
    "       \n",
    "        if is_real:\n",
    "            threshold = split\n",
    "            left_mask = X[attr] <= threshold\n",
    "            right_mask = X[attr] > threshold\n",
    "        else:  \n",
    "            threshold = split\n",
    "            left_mask = X[attr] == threshold\n",
    "            right_mask = X[attr] != threshold\n",
    "\n",
    "        left_child = self._build_tree(data[left_mask], target_col, depth + 1)\n",
    "        right_child = self._build_tree(data[right_mask], target_col, depth + 1)\n",
    "\n",
    "        return self.Node(attribute=attr, threshold=threshold, left=left_child,\n",
    "                         right=right_child, is_real=is_real)\n",
    "\n",
    "    def predict_row(self, row, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "\n",
    "        if node.is_real:\n",
    "            if row[node.attribute] <= node.threshold:\n",
    "                return self.predict_row(row, node.left)\n",
    "            else:\n",
    "                return self.predict_row(row, node.right)\n",
    "        else:  # discrete\n",
    "            if row[node.attribute] == node.threshold:  \n",
    "                return self.predict_row(row, node.left)\n",
    "            else:\n",
    "                return self.predict_row(row, node.right)\n",
    "\n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        return data.apply(lambda row: self.predict_row(row, self.root), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437f20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRealOutput Results on Auto MPG dataset:\n",
      "RMSE: 7.301\n",
      "MAE:  6.134\n"
     ]
    }
   ],
   "source": [
    "target_col = \"mpg\"\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "tree = DecisionTreeRealOutput(max_depth=5)\n",
    "tree.fit(train, target_col=target_col)\n",
    "\n",
    "\n",
    "y_pred = tree.predict(test.drop(columns=[target_col]))\n",
    "y_true = test[target_col]\n",
    "\n",
    "rmse_val = rmse(y_true, y_pred)\n",
    "mae_val = mae(y_true, y_pred)\n",
    "\n",
    "print(\"DecisionTreeRealOutput Results on Auto MPG dataset:\")\n",
    "print(f\"RMSE: {rmse_val:.3f}\")\n",
    "print(f\"MAE:  {mae_val:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade174c",
   "metadata": {},
   "source": [
    "b) **Model Comparison**  \n",
    "   - Compare the performance of your decision tree model with the **Decision Tree module from scikit-learn**.  \n",
    "   **[0.5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64402ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn DecisionTreeRegressor Results:\n",
      "RMSE: 10.081\n",
      "MAE:  2.296\n",
      "\n",
      "Custom DecisionTreeRealOutput Results:\n",
      "RMSE: 7.301\n",
      "MAE:  6.134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "sk_tree = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "sk_tree.fit(train.drop(columns=[target_col]), train[target_col])\n",
    "\n",
    "\n",
    "y_pred_sk = sk_tree.predict(test.drop(columns=[target_col]))\n",
    "y_true = test[target_col]\n",
    "\n",
    "\n",
    "rmse_sk = mean_squared_error(y_true, y_pred_sk)\n",
    "mae_sk  = mean_absolute_error(y_true, y_pred_sk)\n",
    "\n",
    "print(\"Scikit-learn DecisionTreeRegressor Results:\")\n",
    "print(f\"RMSE: {rmse_sk:.3f}\")\n",
    "print(f\"MAE:  {mae_sk:.3f}\")\n",
    "\n",
    "\n",
    "rmse_custom = mean_squared_error(y_true, y_pred)\n",
    "mae_custom  = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(\"\\nCustom DecisionTreeRealOutput Results:\")\n",
    "print(f\"RMSE: {np.sqrt(rmse_custom):.3f}\")\n",
    "print(f\"MAE:  {mae_custom:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
